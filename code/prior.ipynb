{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from variables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the event file, weights and parts of the regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1293 entries, c.when's to y.gihn\n",
      "Columns: 610 entries, please to begin\n",
      "dtypes: float64(610)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Event file.\n",
    "event_file = pd.read_csv('../data/batchfiles/batch1.gz', \n",
    "                         sep = '\\t', \n",
    "                         low_memory = True,\n",
    "                         engine = 'c')\n",
    "\n",
    "# The word column from the regression dataframe.  \n",
    "speaker_word = pd.read_csv('../data/regression_data.csv',\n",
    "                           usecols=['wordID'],\n",
    "                           dtype={\"wordID\": \"category\"},\n",
    "                           low_memory = True, \n",
    "                           engine = 'c')\n",
    "\n",
    "# Weights. \n",
    "df = xr.open_dataarray('../output/weights/weights_buckeye.nc')\n",
    "weight_matrix = df.to_pandas()\n",
    "weight_matrix = weight_matrix.transpose()\n",
    "weight_matrix.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add prior to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words = speaker_word['wordID'].tolist()\n",
    "words = event_file['outcomes'].tolist()\n",
    "prior_dict = {}\n",
    "\n",
    "# Make a prior dictionary.\n",
    "for index, word in tqdm(enumerate(words)):\n",
    "    if word not in prior_dict.keys(): \n",
    "\n",
    "        prior_all = get_prior(weight_matrix = weight_matrix, word_outcome = word, domain_specific = False)\n",
    "        priors = get_prior(weight_matrix = weight_matrix, word_outcome = word, domain_specific = True)\n",
    "        \n",
    "        prior_dict[word] = {'prior_all': prior_all, \n",
    "                            'prior_segments': priors['Segment'], \n",
    "                            'prior_syllables': priors['Syllable'], \n",
    "                            'prior_context' : priors['Context']} \n",
    "# Save to json. \n",
    "out_file = open(\"../data/prior_dictionary.json\", \"w\")\n",
    "json.dump(prior_dict, out_file, indent = 6)\n",
    "out_file.close()\n",
    "    \n",
    "df = pd.DataFrame({'prior_all': [], 'prior_segments': [], 'prior_syllables' : [], 'prior_context': []})\n",
    "\n",
    "for index, word in enumerate(words):\n",
    "    df.at[index, 'prior_all'] = prior_dict[word]['prior_all']\n",
    "    df.at[index, 'prior_segments'] = prior_dict[word]['prior_segments']\n",
    "    df.at[index, 'prior_syllables'] = prior_dict[word]['prior_syllables']\n",
    "    df.at[index, 'prior_context'] = prior_dict[word]['prior_context']\n",
    "\n",
    "# Loading whole regression dataset.\n",
    "regression_data = pd.read_csv('../data/regression_data.csv', \n",
    "                              dtype={\"speakerID\": \"category\",\"speakerAge\": \"category\", \"speakerGender\": \"category\",\n",
    "                                     \"interviewerGender\": \"category\", \"wordID\": \"category\", \"wordDur\": \"float\",\n",
    "                                     \"wordPOS\": \"category\", \"n_segments\": \"category\", \"n_syllables\": \"category\"}, \n",
    "                              engine = 'c',\n",
    "                              low_memory = True)\n",
    "\n",
    "#result = pd.concat(objects = [regression_data, df], axis = 1)\n",
    "#result.to_csv('../data/regression_data_prior.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add activation to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 780.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.when's None\n",
      "c.please c.the\n",
      "c.when's c.last\n",
      "c.the c.time\n",
      "c.last c.you\n",
      "c.time c.thought\n",
      "c.you c.a\n",
      "c.thought c.game\n",
      "c.a c.was\n",
      "c.game c.fun\n",
      "c.was c.but\n",
      "c.fun c.you're\n",
      "c.but c.going\n",
      "c.you're c.to\n",
      "c.going c.lose\n",
      "c.to c.blank\n",
      "c.lose c.doesn't\n",
      "c.blank c.lose\n",
      "c.doesn't c.this\n",
      "c.lose c.is\n",
      "c.this c.fun\n",
      "c.is c.what\n",
      "c.fun c.a\n",
      "c.what c.double\n",
      "c.a c.jump\n",
      "c.double c.you've\n",
      "c.jump c.gotta\n",
      "c.you've c.be\n",
      "c.gotta c.kidding\n",
      "c.be c.cheater\n",
      "c.kidding c.i\n",
      "c.cheater c.is\n",
      "c.i c.that\n",
      "c.is c.the\n",
      "c.that c.ability\n",
      "c.the c.that\n",
      "c.ability c.only\n",
      "c.that c.a\n",
      "c.only c.few\n",
      "c.a c.warbeasts\n",
      "c.few c.possess\n",
      "c.warbeasts c.to\n",
      "c.possess c.overcome\n",
      "c.to c.their\n",
      "c.overcome c.own\n",
      "c.their c.physical\n",
      "c.own c.limits\n",
      "c.physical c.blood\n",
      "c.limits c.destruction\n",
      "c.blood c.i\n",
      "c.destruction c.won't\n",
      "c.i c.lose\n",
      "c.won't c.then\n",
      "c.lose c.one\n",
      "c.then c.hundred\n",
      "c.one c.rule\n",
      "c.hundred c.number\n",
      "c.rule c.ten\n",
      "c.number c.that's\n",
      "c.ten c.not\n",
      "c.that's c.just\n",
      "c.not c.a\n",
      "c.just c.double\n",
      "c.a c.jump\n",
      "c.double c.that's\n",
      "c.jump c.a\n",
      "c.that's c.bug\n",
      "c.a c.i\n",
      "c.bug c.can't\n",
      "c.i c.predict\n",
      "c.can't c.what\n",
      "c.predict c.she'll\n",
      "c.what c.do\n",
      "c.she'll c.huh\n",
      "c.do c.huh\n",
      "c.huh c.the\n",
      "c.huh c.difference\n",
      "c.the c.between\n",
      "c.difference c.their\n",
      "c.between c.strengths\n",
      "c.their c.is\n",
      "c.strengths c.overwhelming\n",
      "c.is c.this\n",
      "c.overwhelming c.battle\n",
      "c.this c.is\n",
      "c.battle c.already\n",
      "c.is c.over\n",
      "c.already c.but\n",
      "c.over c.i\n",
      "c.but c.never\n",
      "c.i c.expected\n",
      "c.never c.all\n",
      "c.expected c.this\n",
      "c.all c.i\n",
      "c.this c.can't\n",
      "c.i c.calculate\n",
      "c.can't c.what\n",
      "c.calculate c.to\n",
      "c.what c.do\n",
      "c.to c.didn't\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#words = speaker_word['wordID'].tolist()\n",
    "words = event_file['outcomes'].tolist()\n",
    "df = pd.DataFrame({'activation_all': [], 'activation_segments': [], 'activation_syllables' : [], \n",
    "                   'activation_context': []})\n",
    "\n",
    "for index, word in tqdm(enumerate(words[:100])): \n",
    "    if index == 0:\n",
    "        c1 = 'c.' + words[index+1]\n",
    "        c2 = None\n",
    "    elif index == len(words)-1:\n",
    "        c1 = 'c.' + words[index-1]\n",
    "        c2 = None\n",
    "    else:\n",
    "        c1 = 'c.' + words[index-1]\n",
    "        c2 = 'c.' + words[index+1]\n",
    "    \n",
    "    act = activation(word_outcome = word, c1 = c1, c2=c2, \n",
    "           event_files = [event_file], weight_matrix = weight_matrix, \n",
    "           domain_specific = False)\n",
    "    act_domain = activation(word_outcome = word, c1 = c1, c2=c2,  \n",
    "           event_files = [event_file], weight_matrix = weight_matrix, \n",
    "           domain_specific = True)\n",
    "    \n",
    "    df.at[index, 'activation_all'] = act\n",
    "    df.at[index, 'activation_segments'] = act_domain['Segment']\n",
    "    df.at[index, 'activation_syllables'] = act_domain['Syllable']\n",
    "    df.at[index, 'activation_context'] = act_domain['Context']\n",
    "\n",
    "#ende = pd.concat(objects = [regression_data, df], axis = 1)\n",
    "#ende.to_csv('../data/regression_data_activation.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_all</th>\n",
       "      <th>activation_segments</th>\n",
       "      <th>activation_syllables</th>\n",
       "      <th>activation_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028172</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029869</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772025</td>\n",
       "      <td>0.350647</td>\n",
       "      <td>0.401478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025256</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113009</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>0.047616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>0.130923</td>\n",
       "      <td>0.056247</td>\n",
       "      <td>0.056235</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0.287915</td>\n",
       "      <td>0.194566</td>\n",
       "      <td>0.078634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>0.764194</td>\n",
       "      <td>0.350647</td>\n",
       "      <td>0.401478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>0.296851</td>\n",
       "      <td>0.176479</td>\n",
       "      <td>0.094498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3604 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activation_all  activation_segments  activation_syllables  \\\n",
       "0           0.028172             0.008272              0.010000   \n",
       "1           0.029869             0.008207              0.010000   \n",
       "2           0.772025             0.350647              0.401478   \n",
       "3           0.025256             0.004247              0.010000   \n",
       "4           0.113009             0.053482              0.047616   \n",
       "...              ...                  ...                   ...   \n",
       "3599        0.130923             0.056247              0.056235   \n",
       "3600        0.287915             0.194566              0.078634   \n",
       "3601        0.079600             0.039800              0.020000   \n",
       "3602        0.764194             0.350647              0.401478   \n",
       "3603        0.296851             0.176479              0.094498   \n",
       "\n",
       "      activation_context  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "...                  ...  \n",
       "3599                 0.0  \n",
       "3600                 0.0  \n",
       "3601                 0.0  \n",
       "3602                 0.0  \n",
       "3603                 0.0  \n",
       "\n",
       "[3604 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Segment': 0.00820677189592, 'Syllable': 0.010000000000000002, 'Context': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation(word_outcome = \"when's\", c1 = 'please', c2='the',  \n",
    "           event_files = [event_file], weight_matrix = weight_matrix, \n",
    "           domain_specific = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = weight_matrix.index\n",
    "if 'please' in i:\n",
    "    print('yes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
